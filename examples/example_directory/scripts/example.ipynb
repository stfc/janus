{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('cc-hdnnp-Ufmq_e4K-py3.8')"
  },
  "interpreter": {
   "hash": "014a019344473c251a50cb45dcadf8d9c61fae40c5010d2c3a9b5a9dfbb2eb38"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Example Workflow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Assumed directory structure\n",
    "\n",
    "```\n",
    "example_directory\n",
    "├── active_learning\n",
    "│   └── simulation.lammps\n",
    "├── cp2k_input\n",
    "│   └── example_template.inp\n",
    "├── cp2k_output\n",
    "├── lammps\n",
    "│   └── template.lmp\n",
    "├── n2p2\n",
    "│   └── input.nn.template\n",
    "├── scripts\n",
    "│   ├── example.ipynb\n",
    "│   └── template.sh\n",
    "├── xyz\n",
    "└── example_trajectory.history\n",
    "```\n",
    "\n",
    "While functions allow for filepaths to be specified, the default arguments will assume the above directory structure, and will read and write to locations accordingly.\n",
    "\n",
    "Another aspect of how the code handles paths is the formatting of file names when creating multiple files with a regular naming pattern. For example, as only a single trajectory is expected this is given with a full file name (e.g. `'example_trajectory.history'`) but the individual frames should contain a pair of braces to allow formatting (e.g. `'xyz/{}.xyz'`).\n",
    "\n",
    "Finally, there is a reliance on \"template\" files which contain details that are not needed to be configured between different frames etc. To change these, simply modify the template files.\n",
    "\n",
    "The majority of file management commands are called via the `Data` object. This stores information about the directory structure, location of executables and the properties of the atoms in question. The latter in turn uses `Species` and `Structure` objects to store information."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from cc_hdnnp.data import Data\n",
    "from cc_hdnnp.structure import AllSpecies, AllStructures, Species, Structure\n",
    "\n",
    "# Create objects for all elements in the structure\n",
    "H = Species(symbol='H', atomic_number=1, mass=1.00794)\n",
    "C = Species(symbol='C', atomic_number=6, mass=12.011)\n",
    "O = Species(symbol='O', atomic_number=8, mass=15.9994)\n",
    "\n",
    "# Define a name for the Structure which has the above constituent elements\n",
    "# Information used for active learning, such as the energy and force tolerances is also defined here\n",
    "all_species = AllSpecies(H, C, O)\n",
    "structure = Structure(name='mcresol', all_species=all_species, delta_E=1e-4, delta_F=1e-2)\n",
    "all_structures = AllStructures(structure)\n",
    "\n",
    "main_directory = '../../m_cresol/all_frames'\n",
    "n2p2_bin = '/home/vol00/scarf860/cc_placement/n2p2/bin'\n",
    "lammps_executable = '/home/vol00/scarf860/cc_placement/lammps/build/lmp_mpi'\n",
    "\n",
    "d = Data(\n",
    "    structures=all_structures,\n",
    "    main_directory=main_directory,\n",
    "    n2p2_bin=n2p2_bin,\n",
    "    lammps_executable=lammps_executable,\n",
    "    n2p2_sub_directory='n2p2_AL_only'\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Generate atomic configurations\n",
    "There are no utility scripts for the generation of configurations, however a full trajectory can be converted into individual frames by:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d.read_trajectory(file_trajectory='example_trajectory.history')\n",
    "d.write_xyz(file_xyz='xyz/{}.xyz')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Write CP2K\n",
    "Both batch scripts and input files for CP2K can be generated by: "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TODO Currently the cp2k commands are not written by the python script, but should be present in\n",
    "# `file_batch`\n",
    "d.write_cp2k(file_batch='scripts/cp2k_batch_{}.bash',\n",
    "             file_input='cp2k_input/example_{}.inp',\n",
    "             file_xyz='xyz/{}.xyz',\n",
    "             n_config=1,\n",
    "             cutoff=(400, 600, 800),\n",
    "             relcutoff=(40, 60, 80))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this case, we have generated 9 input files and 9 batch scripts by specifying 3 values for `cutoff` and `relcutoff`. These can then be used to determine the best values for these settings (that balances accuracy with time taken).\n",
    "\n",
    "## 3. Run CP2K\n",
    "The previous step should output `bash ../scripts/all.bash`. This bash script will submit all the batch scripts which will submit Slurm jobs for all 9 cases."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!bash ../scripts/all.bash"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## 4. Choose (rel)cutoff\n",
    "To extract the useful information from the CP2K output, the following function will print a table comparing energy, time taken and grid allocation:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d.print_cp2k_table(n_config=1, cutoff=(400, 600, 800), relcutoff=(40, 60, 80))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once the best value is chosen, to run CP2K with more frames (larger `n_config`) repeat steps 2. and 3. but with different arguments:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d.write_cp2k(file_batch='scripts/cp2k_batch_{}.bat',\n",
    "             file_input='cp2k_input/example_{}.inp',\n",
    "             file_xyz='xyz/{}.xyz',\n",
    "             n_config=101,\n",
    "             cutoff=(600),\n",
    "             relcutoff=(60))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!bash ../scripts/all.bash"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Write N2P2\n",
    "Once force and energy values are obtained from CP2K, these can be written to the N2P2 data format. The structure name should match one of the structures in `all_structures`:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d.write_n2p2_data(\n",
    "    structure_name=\"mcresol\",\n",
    "    file_cp2k_out='cp2k_output/example_n_{}_cutoff_600_relcutoff_60.log',\n",
    "    file_cp2k_forces='cp2k_output/example_n_{}_cutoff_600_relcutoff_60-forces-1_0.xyz',\n",
    "    file_xyz='xyz/{}.xyz',\n",
    "    file_n2p2_input='input.data',\n",
    "    n_config=101)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Multiple different symmetry functions can be written to the same network input file, for example both shifted and centered versions of the radial, wide and narrow functions:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d.write_n2p2_nn(file_template='input.nn.template',\n",
    "                file_nn='input.nn',\n",
    "                r_cutoff=12.0,\n",
    "                type='radial',\n",
    "                rule='imbalzano2018',\n",
    "                mode='center',\n",
    "                n_pairs=5)\n",
    "d.write_n2p2_nn(file_template='input.nn.template',\n",
    "                file_nn='input.nn',\n",
    "                r_cutoff=12.0,\n",
    "                type='angular_narrow',\n",
    "                rule='imbalzano2018',\n",
    "                mode='center',\n",
    "                n_pairs=5,\n",
    "                zetas=[1])\n",
    "d.write_n2p2_nn(file_template='input.nn.template',\n",
    "                file_nn='input.nn',\n",
    "                r_cutoff=12.0,\n",
    "                type='angular_wide',\n",
    "                rule='imbalzano2018',\n",
    "                mode='center',\n",
    "                n_pairs=5,\n",
    "                zetas=[1])\n",
    "d.write_n2p2_nn(file_template='input.nn.template',\n",
    "                file_nn='input.nn',\n",
    "                r_cutoff=12.0,\n",
    "                type='radial',\n",
    "                rule='imbalzano2018',\n",
    "                mode='shift',\n",
    "                n_pairs=5)\n",
    "d.write_n2p2_nn(file_template='input.nn.template',\n",
    "                file_nn='input.nn',\n",
    "                r_cutoff=12.0,\n",
    "                type='angular_narrow',\n",
    "                rule='imbalzano2018',\n",
    "                mode='shift',\n",
    "                n_pairs=5,\n",
    "                zetas=[1])\n",
    "d.write_n2p2_nn(file_template='input.nn.template',\n",
    "                file_nn='input.nn',\n",
    "                r_cutoff=12.0,\n",
    "                type='angular_wide',\n",
    "                rule='imbalzano2018',\n",
    "                mode='shift',\n",
    "                n_pairs=5,\n",
    "                zetas=[1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Scale and prune symmetry functions\n",
    "Before training, the input data can optionally be normalised. This will apply headers in the relevant n2p2 files, but the other values in `input.data` will remain unchanged. Additionally, the symmetry functions must be \"scaled\", and in order to make the training process less expensive they can also be \"pruned\". Those with a low range across the `input.data` are deemed to be less desirable than those that vary a lot, and are commented out of `input.nn`.\n",
    "\n",
    "## 7. Train network\n",
    "Provided there are an acceptable number of symmetry functions after pruning (if not step 6 can be re-run with a higher or lower threshold) the network can now be trained.\n",
    "\n",
    "The batch scripts for steps 6 and 7 are generated by the following:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d.write_n2p2_scripts(range_threshold=1e-4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!sbatch ../scripts/n2p2_prune.bat\n",
    "!sbatch ../scripts/n2p2_train.bat"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The most recent weights (those from the last epoch) are copied and renamed to the format `weights.<atomic_number>.data`. If for whatever reason a different epoch is desired, then the files should be renamed manually.\n",
    "\n",
    "## 8. Active Learning\n",
    "It is likely that the initial reference structures/energies used for training do not fully describe the system. By training a second network on the same data, active learning can be used to extend the reference structures and energies in regions where the two networks do not agree. Assuming there are two such networks in directories in `../n2p2_1` and `../n2p2_2`, the first step is to generate the necessary LAMMPS input files:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from active_learning import ActiveLearning\n",
    "a = ActiveLearning(data_controller=d, n2p2_directories=['../n2p2_1', '../n2p2_2'])\n",
    "a.write_lammps()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then run LAMMPS using the appropriate batch script:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!sbatch ../scripts/active_learning_lammps.sh"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The trajectories generated by LAMMPS are pre-analysed and where appropriate reduced, before writing the new configurations to be considered to file:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a.prepare_lammps_trajectory()\n",
    "a.prepare_data_new()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then run the NNs using the appropriate batch script to evaluate the energies for this data:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!sbatch ../scripts/active_learning_nn.sh"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the energy evaluations of the NNs, the configurations to add to the training set can be determined by:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a.prepare_data_add()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If the configurations in `input.data-add` seem reasonable, this can be added to the existing data in the n2p2 folders with:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a.combine_data_add()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then the training can be restarted with a wider selection of data to ensure a more applicable model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 9. Write LAMMPS\n",
    "To set up LAMMPS with data from an existing `.xyz` file, the `write_lammps_data` functon can be used. The interaction is defined by `write_lammps_pair`, which creates a LAMMPS input file based on the template provided:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "d.write_lammps_data(file_xyz='xyz/0.xyz', lammps_unit_style='metal')\n",
    "d.write_lammps_pair(r_cutoff=6.351,\n",
    "                    file_template='lammps/template.lmp',\n",
    "                    file_out='lammps/md.lmp',\n",
    "                    n2p2_directory='n2p2',\n",
    "                    lammps_unit_style='metal')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 10. Run LAMMPS\n",
    "Finally, LAMMPS can be run using the the neural network potential defining the interactions."
   ],
   "metadata": {}
  }
 ]
}